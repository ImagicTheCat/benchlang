ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc: left
:toclevels: 5

= benchlang

This project aims to be a tool, a collection of measures and a website about benchmarking languages and their implementations. Measures are nice; interpretation of those measures is up to human beings.

Website: https://imagicthecat.github.io/benchlang/

.Dependencies
* GNU/Linux (may extend to POSIX systems)
* g++
* `find` command
* LuaJIT
* luarocks `lua-messagepack`, `argparse` (5.1)
* anything that the environments require

.Build
[source, sh]
----
# build lib
./build.sh

# download submodules
git submodule init
git submodule update
----

.Usage examples
[horizontal]
help:: `luajit benchmark.lua -h`
basic usage:: `luajit benchmark.lua <host> [options]`
test an implementation:: `luajit benchmark.lua my_host -lc -e gcc -w fibonacci-nr -i my_impl.c`
comparison:: `luajit benchmark.lua my_host -w fibonacci-nr -llua -lc`

TIP: Any specific language, work, environment or implementation names can be specified to narrow the kind of results to produce. Already valid produced results are not recomputed unless the `--force -f` flag is used.

WARNING: No safety/sandboxing is implemented for the executed scripts/programs.

== Concepts

Measures are generated in the `results/` directory for a specific host, a specific language, a specific environment, a specific work and a specific implementation of this work.

Each result file is bound to a specific work/environment's version and an implementation's content (hash), if they change, the result file will be ignored by the site/reports (and recomputed by the benchmark script).

=== Language

A programming language.

NOTE: It's a matter of choice to decide if language versions are defined as different languages or different environments; it may be better to have them as environments and hint the version in the implementation name.

=== Environment

A specific language builder/VM/etc executing an implementation's source code.

TIP: The script may use OS environment variables to adapt to the user system.

=== Work

Something that must be done by the languages; Different set of parameters and expected outputs are used to verify that the work has been done correctly.

=== Implementation

An implementation of a specific work in a specific language.

All implementations will run in each language's environment, but they are not required to work on all of them; the result will just be invalid for those.

TIP: Implementation's file name may contain anything concise and useful to identify it, but using the algorithm/work's name is useless; this information is already present in the file path.

=== Host

Describes all the information about the machine/OS where the work is executed and common parameters used to generate the results for all languages.

== Contributions

Contributions of hosts, results, works, languages, environments and implementations are welcomed.

.Notes
hosts, results:: specific host and associated results should probably be maintained by the same machine owner
languages, environments:: when adding a new language, add a basic standard environment
implementations::
+
--
* changes to an existing implementation will invalidate all computed results, forking the implementation may be a better practice
* implementations should explicit their own license/authors in the source file (when they don't, they are direct parts of the project and use the same license)
* they should not be tuned to specific work steps' parameters, but can be tuned for general practical parameters
* they should only use features generally expected to be available for specific the hosts, language and environments they might run in (in other words, avoid being tuned for the benchmark environment)
* they should comply to the associated work rules (constraints, etc)

NOTE: Some works may impose constraints to narrow the meaning of measures, others may give complete freedom to make the implementation as good as possible (looking at the best implementations may give insight about the complexity of such codes and if it's worth the effort).
--

== File organization

[horizontal]
`hosts/<host>.lua`:: host files
`works/<work>.lua`:: work files
`langs/<lang>/config.lua`:: lang files
`langs/<lang>/envs/<env>.lua`:: environment files
`langs/<lang>/impls/<work>/<impl>`:: implementation files
`results/<host>/<lang>/<env>/<work>/<impl>.data`:: result files

== Results

Multiple measures will probably be taken for each work/parameters couple, they will be aggregated for the website/reports.

.Aggregation for final reported measures
[horizontal]
memory:: take maximum of all measures
time:: take minimum of all measures
